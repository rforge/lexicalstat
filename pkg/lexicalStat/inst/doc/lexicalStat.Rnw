\documentclass{article}
%\VignetteIndexEntry{Introduction to lexicalStat}
\usepackage{lmodern}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{dcolumn}
%\usepackage[francais]{babel}

\makeindex 

\title{Introduction to the lexicalStat package}

\author{Bernard Desgraupes and Sylvain Loiseau\\
<bernard.desgraupes@u-paris10.fr>, <sylvain.loiseau@univ-paris13.fr>}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
The \texttt{lexicalStat} R library provide functions for reading corpora,
converting them between several representations, and applying exploratory
functions like word attraction measure and keyword in context.
\end{abstract}

\vspace{5mm}
\hrule
\tableofcontents
\vspace{5mm}
\hrule

\newpage

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{Introduction}
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\label{sec:Intro}

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{Sample sessions}
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\label{sec:sample}

These sample sessions show typical use of this package.

\subsection{Cooccurrents of \emph{action} in daily newspaper articles}

A plain text file contains articles extracted from the economic section of a daily
newspaper (French newspaper \emph{Le Monde}). The corpus is read, segmented in
sentences and tokenzied. A subcorpus is created by extracting the sentences
containing \emph{actionnaire}. Which lexical types are over-frequent in this subcorpus?
The 25 types most strongly over-frequent (according to the log-likelihood measure)
are printed.

<<sample_session1_1, echo=T>>=
library(lexicalStat);
fileName <- system.file(c("exempleData"),
                        "LeMondeEco.lines",
                        package="lexicalStat")
c <- readTexts(fileName, split.on="sentences");
sc <- subcorpus(c, "actionnaire");
w <- wam(as.FrequencyList(c), subcorpus=as.FrequencyList(sc), measure="wam.loglikelihood");
print(w, from=1, to=25);
@

\subsection{Inspect context of \emph{action} trough a concordancer (KWIC)}

<<sample_session2, echo=T>>=
library(lexicalStat);
fileName <- system.file(c("exempleData"),
                        "LeMondeEco.lines",
                        package="lexicalStat")
t <- readTexts(fileName, split.on="sentences");
c <- kwic(t, "actionnaire");
c[1:10,]
@

\subsection{Specific words of the different novels by an author}

A directory contains files, each of whom contains a novel by the novelist Emile Zola.
Which are the word distinguishing each novels? (here, only the first paragraphs for
only three novels are given).

<<sample_session3, echo=T>>=
#dir <- system.file(c("exempleData", "zola"),
#                        package="lexicalStat")
#c <- readTexts(dir=dir, split.on="files");
#wam(c);
@

\subsection{Cooccurrents of a word in a tagged corpus}

The text of a dictionary has been tagged by a part-of-speech tagger (here, treetagger).
The XML elements \emph{def} and \emph{cit} where used for distinguishing definitions
and examples. Which are the specific forms used in the exemple?

<<sample_session4, echo=T>>=
fileName <- system.file(c("inst", "exempleData"), 
              "PetitLarousse1905.ttg", package="lexicalStat")
tabulated <- read.treetagger(fileName);
head(tabulated)

sc <- subcorpus(tabulated, "cit")

scl <- as.FrequencyList(sc, "word");
cl <- as.FrequencyList(tabulated, "word")

w <- wam(cl, subcorpus=scl, measure="wam.loglikelihood");
print(w, from=1, to=20);
@

\subsection{Robespierre}

A lexical table contains the word frequencies in 10 discourses (nammed \texttt{D1},
\texttt{D2}, \ldots \texttt{D10}) by Maximilien de Robespierre. Here are the first lines:

<<sample_session5, echo=T>>=
data(robespierre);
#head(robespierre);
@

For the first and the last discours, which are the 10 most characteristic words?

<<sample_session5, echo=T>>=
#w <- wam(robespierre, measure="loglikelihood");
#print(w, from=1, to=20, parts=c("D1", "D10"));
@

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{Representing corpora}
% ----------------------------------------------------------------
% ----------------------------------------------------------------
\label{sec:classes}

% ----------------------------------------------------------------
\subsection{Classes for representing corpora}
% ----------------------------------------------------------------
\label{subsec:classes-corpora}

There are four classes for representing a corpus. Each is suited for some tasks
or for some sources.

All classes have the three following basic functions:
\begin{itemize}
\item \texttt{N}\index{N} : the number of tokens in the corpus
\item \texttt{V}\index{V} : the number of different types (V stand for vocabulary)
\item \texttt{types}\index{types} : the sorted list of the different types.
\end{itemize}
Each of them has also specific functions. The function \texttt{summary}\index{summary}
applied on this data structures provide short resumes of their content.

% TODO : classes not types
For each of these four types, a ready-to-use tool corpus is provided as a
dataset (dataset are objects that can be easily loaded into the R environnement with the
function \texttt{data}). All of these tool-corpora represent the two first sentences
of \textit{A Christmas Carol} by Ch. Dickens. They are:

\begin{itemize}
\item \texttt{dickensFrequencyList}
\item \texttt{dickensLexicalTable}
\item \texttt{dickensTabulated}
\item \texttt{dickensFullText}
\end{itemize}

In this section the structure and basic functionalities for each of these four classes
are presented.

In the next sections we will see the functions
for extracting subcorpora (p.~\pageref{subsec:subcorpora}),
for converting from one format
toward another (p.~\pageref{sec:classes}) and for
creating this data structures with files containing
actual corpora (p.~\pageref{subsec:read-corpora}).

% ................................................................
\subsubsection{\texttt{frequencyList}}
% ................................................................
\label{subsubsec:classes-frequencyList}
\index{frequencyList corpus class}

A frequencyList is the most compact representation of a corpus: it is a simple mapping
between types and \textbf{total frequency} :

\vskip 1em

\begin{tabular}{lr}\hline
Type & Frequency\\\hline
peuple & 296\\
republique & 207\\
ennemi & 165\\
patrie & 153\\
\ldots & \ldots\\\hline
\end{tabular}

\vskip 1em

A frequency list is simply a data frame with two columns, \texttt{type} and
\texttt{frequency}. It can be used as any other data frame, but suited functions
are also provided. They are, first, the very general functions: \texttt{N}\index{N},
\texttt{V}\index{V}, \texttt{summary}\index{summary} and \texttt{types}\index{types}.

<<frequencyList_common_functions, echo=T>>=
data(dickensFrequencyList);
head(dickensFrequencyList);
N(dickensFrequencyList)
ntype(dickensFrequencyList)
summary(dickensFrequencyList);
types(dickensFrequencyList);
@

There are also functions for fetching the frequency of given types
(\texttt{freq}\index{freq})
or for asking if a given type is available in this frequency list
(\texttt{has.type}\index{have.type}).

<<frequencyList_other_functions, echo=T>>=
freq(dickensFrequencyList, c("the", "."))
contains.types(dickensFrequencyList, c("the", "blabla"))
@

A frequency list can be created with a named numeric vector thanks to the function
\texttt{frequencyList}\index{frequencyList}:

<<frequencyList, echo=T>>=
library(lexicalStat);
x <- c(10, 2, 3, 50)
names(x) <- c("type1", "type2", "type3", "type4");
y <- frequencyList(x);
y
summary(y);
@

It can also be created with a two-columns data.frame or a
\texttt{table}\index{table} object.

% \item \texttt{hapax}\index{hapax} the list of types which appears only once in the corpus

% ................................................................
\subsubsection{\texttt{lexicalTable}}
% ................................................................
\label{subsubsec:classes-lexicalTable}
\index{lexicalTable corpus class}

In a \textbf{lexical table}\index{lexical table} the rows give the forms found in
the corpus, the columns give differents sub-parts of the corpus. Each cell of the table gives
subfrequency of the corresponding type in the corresponding sub-part
(see table \ref{tab:lexicaltable-sample} p.~\pageref{tab:lexicaltable-sample}).
A lexical table is a \textbf{contingency table}.

Here is the first lines for the \texttt{dickensLexicalTable} lexical table, giving the frequency
for the different types across 10 discourses :

<<label=lexicalTable1,echo=FALSE,results=tex>>=
library(xtable)
data(dickensLexicalTable);
x <- as.matrix(dickensLexicalTable)[1:10,];
x <- rbind(x, rep("...", 10))
rownames(x)[11] <- "..." 
print(xtable(as.data.frame(x), align=c("l", rep("r", 3)),
    caption = "Frequency table: Dickens",
    label = "tab:lexicaltable-sample",
    digits = 0), table.placement = "h",
    caption.placement = "top")

#library(xtable)
#data(robespierre);
#x <- as.matrix(robespierre)[1:10,];
#x <- rbind(x, rep("...", 10))
#rownames(x)[11] <- "..." 
#print(xtable(as.data.frame(x), align=c("l", rep("r", 10)),
#    caption = "Robespierre discourses (frequency table)",
#    label = "tab:lexicaltable-sample",
#    digits = 0), table.placement = "h",
#    caption.placement = "top")
@

A \textbf{part} is a subset of a corpus and, thus, a \textbf{subcorpus}. But it is a
special kind of subcorpus, belonging to a set of such subcorpus that divide exhaustively the corpus,
and that are most probably corresponding to an object of analysis -- here, different discourses.

Lexical table is a compact way of representing frequence information and to
study variation of frequency of a type accross parts.

A lexical table object have the \texttt{N}\index{N}
\texttt{ntype}\index{ntype} and
\texttt{types}\index{types}
functions:

<<label=lexicalTable2,echo=TRUE>>=
data(robespierre);
#head(robespierre);
summary(robespierre);
N(robespierre);
ntype(robespierre);
types(robespierre)[1:10];
@

A lexical table can be created from any numerical matrix through the function
\texttt{lexicalTable}\index{lexicalTable}. They are represented using
sparse matrix (from the package \texttt{Matrix}).

% ................................................................
\subsubsection{\texttt{tabulated}}
% ................................................................
\label{subsubsec:classes-tabulated}
\index{tabulated corpus class}

A tabulated corpus is a more complexe representation. It does not sum-up only the frequencies
but record all the concrete occurrences of the different types in their actual order.
In addition:

\begin{itemize}
\item (1) several representation can be recorded for each token (such as inflected
form\index{inflected form}, lemma\index{lemma} and pos\index{pos}). 
\item (2) several groupings of the tokens of the corpus can be represented.
\end{itemize}

%(1) In the \texttt{lexicalTable} object, each token has been considered through one
%representation (lemma, pos, inflected form \ldots) in order to be counted. And
%the \texttt{lexicalTable} show distribution of this token across one partition
%(the column) of the table.

(1) A tabulated corpus is a table where each line represent a token. There is several column
corresponding to the different representation available for each token (inflected form,
pos, lemma, \ldots) : see table \ref{tab:tabulated-sample1}.

%x <- as.data.frame(x, stringsAsFactors=F)
%x <- rbind(x, rep("...", 3))
%rownames(x)[11] <- "..." 

<<label=tabulated1,echo=FALSE,results=tex>>=
fileName <- system.file(c("inst", "exempleData"), "sample.ttg", package="lexicalStat")
tabulated <- read.treetagger(fileName);
x <- tabulated[1:10,1:3]
print(xtable(as.data.frame(x), align=c("l", rep("l", 3)),
    caption = "First tokens of a corpora in a tabulated representation",
    label = "tab:tabulated-sample1",
    digits = 0), table.placement = "h",
    caption.placement = "top")
@

(2) They may be additional columns. Each such column correspond to a kind of \textbf{grouping}
of tokens. It can be seen as an XML element. Consecutive token sharing the same value in
such a columns belong to a same group, as if they where surrounded by a tag pair of that
XML element. Value \texttt{-1} in these columns means that we are outside any group.

The table \ref{tab:tabulated-sample2} (p.~\pageref{tab:tabulated-sample2}) shows the same
example as above with 4 such columns. The first token belong to a group of type "form". The
following tokens belong to a group of type "def".

<<label=tabulated1,echo=FALSE,results=tex>>=
fileName <- system.file(c("inst", "exempleData"), "PetitLarousse1905.ttg", package="lexicalStat")
tabulated <- read.treetagger(fileName);
x <- tabulated[1:10,]
data(robespierre);
print(xtable(as.data.frame(x), align=c("l", rep("l", 7)),
    caption = "First tokens of a corpora in a tabulated representation",
    label = "tab:tabulated-sample2",
    digits = 0), table.placement = "h",
    caption.placement = "top")
@

It can be seen in an XML representation :

\begin{verbatim}
<EntryFree>
<form>
baba	ADJ	baba
</form>
<def>
Gâteau	NOM	gâteau
[...]
\end{verbatim}

Column of the first kind are called \textbf{positional} and column of the second are called
\textbf{structural}\footnote{This terminology, as well as this representation, is inspired by the representation found in the
\texttt{CWB}\index{CWB} corpus software (see package
\texttt{rcqp}\index{rcqp}).}.

The functions
\texttt{lpositional}\index{lpositional} and
\texttt{lstructural}\index{lstructural} allow for retreiving the name of the columns of
the two different kinds :

<<label=lexicalTable2,echo=TRUE>>=
data(dickensTabulated);
lpositional(dickensTabulated);
lstructural(dickensTabulated);
@

This format is suited for representing tabulated files\index{tabulated files},
such as files produced by part-of-speech tagger\index{tagger}.

The usual \texttt{N}\index{N}, \texttt{V}\index{V}, \texttt{summary}\index{summary}
and \texttt{types}\index{types} functions are available. Besides these extra functions
(and other functions, bellow), tabulated object are data frame.

% ................................................................
\subsubsection{\texttt{fullText}}
% ................................................................
\label{subsubsec:classes-fullText}
\index{fullText corpus class}

The \texttt{fullText} class is the most simplistic representation of a corpus:
it is a list where each slot contains a vectors of tokens. The list represent a
partition\index{partition} of the corpus.

This format is suited for representing plain text file\index{Reading text
files} (see bellow how to read files).

\texttt{summary} and \texttt{print} functions pretty print a fullText corpus.

<<fullText, echo=TRUE>>=
library(lexicalStat);
data(dickensFullText)
summary(dickensFullText)
dickensFullText
@

A fullText object is basicaly a list of character vectors.

% ----------------------------------------------------------------
\subsection{Extracting sub-corpora}
% ----------------------------------------------------------------
\label{subsec:subcorpora}

TODO

% ----------------------------------------------------------------
\subsection{Conversion between classes}
% ----------------------------------------------------------------
\label{sec:classes}

(\texttt{fullText} <-> \texttt{tabulated}) -> \texttt{lexicalTable} -> \texttt{frequencyList}

The first two data structures represent the linearity of tokens and can be used
for producing concordancer\index{concordancer} or any "readable" form of the
corpus.

The last two are "bags of words"\index{bag of words} : they do not save
represent order of the tokens and keep only frequency. The penultimate keep the
distribution of sub-frequency between parts of a corpus, while the last one
represent only total frequency.

The first two data structures can be converted back and forth. 

A \texttt{lexicalTable} can be created only thanks to a \texttt{fullText} or a
\texttt{tabulated} corpora. A \texttt{frequencyList} can be created only thanks
to a \texttt{lexicalTable}.

Thus, the function \texttt{asFullText}\index{asFullText} can be applied on
\texttt{tabulated} corpora; the function
\texttt{asTabulated}\index{asTabulated} can be used with \texttt{fullText}
corpora; the \texttt{asLexicalTable}\index{asLexicalTable} function can be
applied on \texttt{tabulated} and \texttt{fullText} corpora; the
\texttt{asFrequencyList}\index{asFrequencyList} function can be applied only to
\texttt{lexicalTable} corpora.

Note that when converting a tabulated object into any other object, you have to
specify which positional column should be kept (in order to count the number of
occurrence of each type in order to produce a frequency list, you have to specify
if the inflected forms, the pos or the lemma has to be considered). If you turn
a tabulated object into a lexicalTable or a fullText object, you have also to
indicate which structural column give the "part".

EXAMPLE TODO

% ----------------------------------------------------------------
\subsection{Read corpora from files}
% ----------------------------------------------------------------
\label{subsec:read-corpora}

TODO

% ................................................................
\subsubsection{\texttt{frequencyList}}
% ................................................................
\label{subsubsec:read-frequencyList}

% ................................................................
\subsubsection{\texttt{lexicalTable}}
% ................................................................
\label{subsubsec:read-lexicalTable}

function
\texttt{readLexicalTable}\index{readLexicalTable})

<<tabulated, echo=TRUE>>=
  base <- paste(system.file(package = "lexicalStat"), "exempleData", "lemonde", sep="/")
  x <- readLexicalTable(base);
  summary(x);
  print(x[1:10, 1:5]);
@

% ................................................................
\subsubsection{\texttt{tabulated}}
% ................................................................
\label{subsubsec:read-tabulated}

 The function
\texttt{read.treetagger} read a file produced by treetagger\index{treetagger}
and produce a \index{tabulated} corpus. If the file analysed was an XML
document, treetagger may conserve the XML element. In this case, they are
turned by \texttt{read.treetagger} into supplementary columns, where tokens
belonging to the same element share the same value.

<<tabulated, echo=TRUE>>=
  fileName <- system.file(c("exempleData"), "sample.ttg", package="lexicalStat")
  tabulated <- read.treetagger(fileName);
  summary(tabulated);
  print(tabulated);
@

% ................................................................
\subsubsection{\texttt{fullText}}
% ................................................................
\label{subsubsec:read-fullText}

<<fullText, echo=TRUE>>=
library(lexicalStat);
fileName <- system.file(c("exempleData"),
                        "LeMondeEco.small.lines",
                        package="lexicalStat")
c <- readTexts(fileName);
summary(c);
print(c);
@

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{KWIC}
% ----------------------------------------------------------------
% ----------------------------------------------------------------

TODO

% ----------------------------------------------------------------
% ----------------------------------------------------------------
\section{Word attraction measure}
% ----------------------------------------------------------------
% ----------------------------------------------------------------

% ----------------------------------------------------------------
\subsection{Introduction}
% ----------------------------------------------------------------

"Word attraction measures" are methods for extracting the forms notably
frequent or sparse in a subcorpus by comparison with its parent corpus. These forms
notably frequent or sparse may be very informative for describing the subcorpus.

This is a general comparative method. Depending on how the contrast was built
(i.e. how the subcorpus was built), it may be used for describing various
objects.  For instance:

\begin{itemize}
\item If the subcorpus represent a novel amongst all the novels by an author, it may be
used for describing its thematic or specific content.
\item If the subcorpus gather all immediat contexts of a verb, it may be used for
  describing its cooccurrents (argument, phraseology...)
\item If the subcorpus gather all paragraphs containing a word, it may be used for
  describing the semantic/thematic associated to this word.
\end{itemize}

% ----------------------------------------------------------------
\subsection{Using word attraction measure with the different corpus classes}
% ----------------------------------------------------------------

Word attraction measure needs a corpus and a subcorpus. Depending on the corpus
object you are using, there is various ways of building these arguments.

% ................................................................
\subsubsection{\texttt{frequencyList}}
% ................................................................

With \texttt{frequencyList}, you need a frequencyList representing a corpus and
frequencyList representing a subcorpus.

% ................................................................
\subsubsection{\texttt{lexicalTable}}
% ................................................................

With \texttt{lexicalTable}, the different parts (columns) of the table are used as
subcorpora, and the analysis is produced for each sub subcorpora. As an
argument, you can give the name of of the parts (columns) you're interested in.

<<wam_lexicalTable, echo=TRUE>>=
library(lexicalStat);
data(robespierre);
#w <- wam(robespierre)
#print(w, from=1, to=5)
@

% ................................................................
\subsubsection{\texttt{tabulated}}
% ................................................................

With \texttt{tabulated} corpus, you need to specify a "positional" attribute
(which feature of the tokens (lemma, inflected form, pos...) are used for
counting frequency of occurrences?) and a "structural" attribute (which
grouping of the frequency are used for creating the parts?). These two arguments
allow for the creating of a lexical table.

% ................................................................
\subsubsection{\texttt{fullText}}
% ................................................................

With \texttt{fullText} corpus, all the different parts (element of the list) are
used as subcorpora. Again, the analysis is produced for each subcorpora. You
can use function for merging parts before applying this analysis.

% ----------------------------------------------------------------
\subsection{Available word attraction indicators}
% ----------------------------------------------------------------

% ................................................................
\subsubsection{log-likelihood}
% ................................................................

<<attraction_indicator_loglikelihood, echo=FALSE, fig=TRUE>>=
plot(wam.loglikelihood(61449, 7896, 296, 0:296), type="l", xlab="k", ylab="log-likelihood", main="Log-likelihood indicateur", sub="N=61449, n=7896, K=296")
@

% ................................................................
\subsubsection{Specificities}
% ................................................................

This indicator has been proposed by Lafon in
"Sur la variabilité de la fréquence des formes dans un corpus",
\emph{Mots}, 1, 1980, 127--165
(\url{http://www.persee.fr/web/revues/home/prescript/article/mots_0243-6450_1980_num_1_1_1008}).

It is similar to the binomial indicator but use the hypergeometric distribution.
It takes four arguments:

\begin{itemize}
\item N the total size of the corpus (in number of occurrences)
\item n the size of the sub corpus (in number of occurrences)
\item K the frequency of the form under scrutiny in the corpus
\item k the frequency of the form under scrutiny in the subcorpus
\end{itemize}

Consider these parameters for the lexical form \emph{peuple} in three public discourses
by Robespierre in a corpus of 10 discourses containing $N = 61449$ occurrences in total (Lafon 1980) :

\begin{tabular}{l|rrrr}
Discours & N & n & K & k\\\hline
4 & 61449 & 6903 & 296 & 14  \\
5 & 61449 & 7896 & 296 & 53  \\
8 & 61449 & 2063 & 296 & 16  \\\hline
\end{tabular}

For each line we can compute the expected frequency of the form ($K \times n / N$) and
mark $+$ if the form is more frequent than expected or $-$ otherwise.

\begin{tabular}{l|rrrrrr}\hline
Discours & N & n & K & k & expected & $k > expected$\\\hline
4 & 61449 & 6903 & 296 & 14 & \Sexpr{sprintf("%.2f", round(292 * 6903 / 61449, 2))} & $-$\\ 
5 & 61449 & 7896 & 296 & 53 & \Sexpr{sprintf("%.2f", round(292 * 7896 / 61449, 2))} & $+$\\
8 & 61449 & 2063 & 296 & 16 & \Sexpr{sprintf("%.2f", round(292 * 2063 / 61449, 2))} & $+$\\\hline
\end{tabular}

The form \emph{peuple} is less frequent in the fourth discourse than expected.
On the contrary, \emph{peuple} is more frequent than expected in the fifth and
eigth discourses.

If the observed frequency is less than the expected frequency, we compute the sum of the
probability for a frequency lesser or equal to the observed frequency ($Prob(X \leq k)$).
If the observed frequency is greater than the expected frequency, we compute the sum of the
probability for a frequency greater to the observed frequency ($Prob(X > k)$) (Lafon 1980 : 152).

In both cases, the more unexpected is the frequency, the smaller is the indicator.

\begin{tabular}{l|rrrrrrr}\hline
Discours & N & n & K & k & expected & $k > expected$ & cumulative extreme probability\\\hline
4 & 61449 & 6903 & 296 & 14 & \Sexpr{sprintf("%.2f", round(292 * 6903 / 61449, 2))} & $-$ & \Sexpr{sprintf("%.10f", phyper(14, 296, 61449-296, 6903))}\\
5 & 61449 & 7896 & 296 & 53 & \Sexpr{sprintf("%.2f", round(292 * 7896 / 61449, 2))} & $+$ & \Sexpr{sprintf("%.10f", 1 - phyper(53-1, 296, 61449-296, 7896))}\\
8 & 61449 & 2063 & 296 & 16 & \Sexpr{sprintf("%.2f", round(292 * 2063 / 61449, 2))} & $+$ & \Sexpr{sprintf("%.10f", 1 - phyper(16-1, 296, 61449-296, 2063))}\\\hline
\end{tabular}

According to this indicator, the second case is more "surprising" than the third or, in other
terms, \emph{peuple} is more attracted by, or specific to the second discourse than to the third.

According to relative frequency, one could conclude the other way around:
$ 53 / 7896 = \Sexpr{round(53 / 7896, 4)} < 16 / 2063 = \Sexpr{round(16 / 2063, 4)}$
(cf. Lafon 1980 : 152).

(Eventually, the specificity indicator is built as... the signed probability + the log... ?)

For the fifth discourse above ($N=61449$, $n=7896$), the possible frequencies of
\emph{peuple} range from $0$ to $296$. Here is the corresponding values for the specificities
indicator:

<<wam_otherArguments_types, echo=FALSE, fig=TRUE>>=
plot(wam.specificities(61449, 7896, 296, 0:296), type="l", xlab="k", ylab="specificities", main="Specificities indicateur", sub="N=61449, n=7896, K=296")
#print(xyplot(wam.specificities(61449, 7896, 296, 0:296) + 0:296/7896 ~ 0:296, type = "l"))
#curve(function(x) wam.specificities(61449, 7896, 296, x), from = 0, to = 296)
@


% ----------------------------------------------------------------
\subsection{Other arguments}
% ----------------------------------------------------------------

% ................................................................
\subsubsection{Computing the indicator for some types}
% ................................................................

In every case, you can specify the \texttt{types} for which you want the indicator to be calculated.

<<wam_otherArguments_types, echo=TRUE>>=
library(lexicalStat);
data(robespierre);
#w <- wam(robespierre, types=c("peuple", "patrie"))
@

% ................................................................
\subsubsection{Computing the indicator for some parts}
% ................................................................

When the indicator is computed for several subcorpus (parts of the corpus), you
can specify the \texttt{parts} for which you want the indicator to be
calculated.

<<wam_otherArguments_parts, echo=TRUE>>=
library(lexicalStat);
data(robespierre);
#w <- wam(robespierre, parts=c("D1", "D2"))
#print(w, from=1, to=5)
@

% ................................................................
\subsubsection{Selecting which indicator to use}
% ................................................................

You can specify the indicator you want to be used : log-likelihood,
specificities, fisher, etc. (see section "indicators" bellow for a
presentation). By defaut, the specificities is used. You can even ask for
several indicators:

<<wam_otherArguments_parts, echo=TRUE>>=
library(lexicalStat);
data(robespierre);
#w <- wam(robespierre, measure=c("specificities", "loglikelihood"))
#print(w, from=1, to=5)
@

% ----------------------------------------------------------------
\subsection{Printing options}
% ----------------------------------------------------------------

% ----------------------------------------------------------------
\subsection{Available indicators}
% ----------------------------------------------------------------

\printindex

\end{document}


